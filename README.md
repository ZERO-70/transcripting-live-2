# Live Transcription Stream Project

A real-time transcription system with advanced profanity filtering capabilities and live audio playback.

## ‚ú® Key Features

- **Real-time Transcription**: Live speech-to-text using OpenAI Whisper
- **Advanced Profanity Filtering**: Multiple filtering approaches (dictionary, AI model-based)
- **üîä Live Audio Playback**: Hear the stream audio while viewing transcriptions
- **Multiple Stream Support**: UDP and HTTP streaming protocols
- **Flexible Configuration**: Customizable filters, models, and audio settings
- **Easy-to-Use Interface**: Simple command-line runner for all features

## üìÅ Project Structure

```
üìÅ stream/ (root)
‚îú‚îÄ‚îÄ üìÅ src/              # Main source code
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ filters/      # Profanity filtering implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ profanity_filter.py           # Dictionary-based filter
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enhanced_profanity_filter.py  # Enhanced dictionary filter
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_profanity_filter.py     # AI model-based filter
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_profanity_filter.py      # Filter tests
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ transcription/                  # Transcription functionality
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ live_transcribe.py            # Real-time transcription
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ streaming/                      # Streaming functionality
‚îÇ       ‚îî‚îÄ‚îÄ ffmpeg_stream.py              # Video streaming
‚îú‚îÄ‚îÄ üìÅ config/           # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ profanity_config.json            # Basic filter config
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_profanity_config.json   # Enhanced filter config
‚îÇ   ‚îî‚îÄ‚îÄ model_profanity_config.json      # Model filter config
‚îú‚îÄ‚îÄ üìÅ data/             # Data files and datasets  
‚îÇ   ‚îú‚îÄ‚îÄ hurtlex_EN.tsv                   # Offensive words dataset
‚îÇ   ‚îî‚îÄ‚îÄ offensive_words_en.txt           # Additional word list
‚îú‚îÄ‚îÄ üìÅ tests/            # Test files
‚îÇ   ‚îú‚îÄ‚îÄ test_comprehensive_filters.py    # Comprehensive tests
‚îÇ   ‚îî‚îÄ‚îÄ test_model_filter.py             # Model filter tests
‚îú‚îÄ‚îÄ üìÅ demos/            # Demo scripts
‚îÇ   ‚îú‚îÄ‚îÄ demo_filter_comparison.py        # Filter comparison demo
‚îÇ   ‚îú‚îÄ‚îÄ demo_model_filter.py             # Model filter demo
‚îÇ   ‚îî‚îÄ‚îÄ demo_red_highlighting.py         # Highlighting demo
‚îú‚îÄ‚îÄ üìÅ docs/             # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ COMPLETE_FILTER_GUIDE.md         # Complete filtering guide
‚îÇ   ‚îú‚îÄ‚îÄ MODEL_FILTER_GUIDE.md            # Model filter guide
‚îÇ   ‚îú‚îÄ‚îÄ PROFANITY_FILTER_GUIDE.md        # Profanity filter guide
‚îÇ   ‚îú‚îÄ‚îÄ RED_HIGHLIGHTING_GUIDE.md        # Highlighting guide
‚îÇ   ‚îú‚îÄ‚îÄ TRANSCRIPTION_GUIDE.md           # Transcription guide
‚îÇ   ‚îú‚îÄ‚îÄ VLC_SETUP.md                     # VLC setup guide
‚îÇ   ‚îî‚îÄ‚îÄ IMPLEMENTATION_SUMMARY.md        # Implementation summary
‚îú‚îÄ‚îÄ üìÅ output/           # Generated files
‚îÇ   ‚îú‚îÄ‚îÄ video.mp4                        # Sample videos
‚îÇ   ‚îú‚îÄ‚îÄ video1.mp4
‚îÇ   ‚îî‚îÄ‚îÄ transcript_20250801_204709.txt   # Generated transcripts
‚îú‚îÄ‚îÄ üìÅ temp/             # Temporary files
‚îÇ   ‚îú‚îÄ‚îÄ hls/                             # HLS streaming files
‚îÇ   ‚îî‚îÄ‚îÄ __pycache__/                     # Python cache
‚îî‚îÄ‚îÄ üìÑ requirements.txt  # Python dependencies
```

## üöÄ Features

- **Real-time Transcription**: Live speech-to-text conversion
- **Multiple Profanity Filters**:
  - Dictionary-based filtering
  - Enhanced pattern matching
  - AI model-based toxicity detection
- **Streaming Support**: FFmpeg-based video streaming
- **Configurable**: JSON-based configuration system
- **Red Highlighting**: Visual indication of filtered content

## üìã Requirements

### Prerequisites
- Python 3.8+
- FFmpeg (for streaming)
- VLC media player (optional, for viewing streams)

### Installation

1. **Install dependencies:**
```bash
pip install -r requirements.txt
```

2. **Environment Setup:**
Copy the example environment file and configure your API tokens:
```bash
cp .env.example .env
```

Edit `.env` and add your Hugging Face token:
```
HUGGINGFACE_TOKEN=your_huggingface_token_here
```

Get your Hugging Face token from: https://huggingface.co/settings/tokens

> ‚ö†Ô∏è **Important**: Never commit the `.env` file to version control. It's already included in `.gitignore`.

## üéØ Quick Start

### Using the Runner Script (Recommended)

The easiest way to run any component:

```bash
## üöÄ Quick Start

### With Audio Playback (New!)

```bash
# Basic transcription with live audio playback
python3 run.py transcribe-audio

# With AI model-based filtering and audio
python3 run.py transcribe-audio-model

# List available audio devices first
python3 run.py list-audio-devices

# Custom audio settings
python3 run.py transcribe-audio --audio-volume 0.5 --audio-device 0
```

### Standard Transcription

```bash
# Different filter types
python3 run.py transcribe-dict       # Dictionary-based filter
python3 run.py transcribe-model     # AI model-based filter (accurate)
python3 run.py transcribe-nofilter  # No filtering (raw transcription)
python3 run.py transcribe           # Default (dictionary filter)

# Add audio to any existing component
python3 run.py transcribe-model --enable-audio --audio-volume 0.6
```

# Demo scripts
python3 run.py demo-comparison      # Compare all filter types
python3 run.py demo-model          # Model-based filter demo
python3 run.py demo-highlight      # Red highlighting demo

# Test scripts
python3 run.py test-comprehensive  # Run all tests
python3 run.py test-model          # Test model filters

# Streaming
python3 run.py stream              # Start video streaming
```

### Audio Playback Features

```bash
# List available audio devices
python3 run.py list-audio-devices

# Audio-enabled transcription variants
python3 run.py transcribe-audio              # Basic with audio
python3 run.py transcribe-audio-model        # Model filter + audio
python3 run.py transcribe-audio-dict         # Dictionary filter + audio

# Audio options for any transcription
python3 run.py transcribe --enable-audio --audio-volume 0.7 --audio-device 2

# HTTP streaming with audio
python3 run.py transcribe-audio --stream http --audio-volume 0.5
```

### Advanced Transcription Options

```bash
# Custom Whisper models
python3 run.py transcribe-model --model large

# Different languages
python3 run.py transcribe-dict --language es

# HTTP streaming (more reliable)
python3 run.py transcribe-dict --stream http

# Custom toxicity models
python3 run.py transcribe-model --toxicity-model "unitary/toxic-bert"
```

### Direct Usage

If you prefer to run components directly:

```bash
# Set up Python path first
export PYTHONPATH="$PWD/src:$PWD/src/filters:$PWD/src/transcription:$PWD/src/streaming:$PYTHONPATH"

# Then run components
cd src/transcription && python3 live_transcribe.py --filter-type model
cd demos && python3 demo_filter_comparison.py
cd tests && python3 test_comprehensive_filters.py
```

## üìñ Documentation

### Audio Features
- `AUDIO_PLAYBACK_GUIDE.md` - Comprehensive audio playback guide
- `RUN_PY_AUDIO_GUIDE.md` - Updated run.py usage with audio features

### Core Documentation
- See `docs/` folder for detailed guides
- Configuration examples in `config/` folder
- Demo scripts in `demos/` folder

## üîß Configuration

Edit configuration files in `config/` to customize:
- Filter sensitivity levels
- Action types (highlight, censor, remove)
- Model parameters
- Toxicity thresholds

---

**Author**: ZERO-70  
**Version**: 1.0.0
